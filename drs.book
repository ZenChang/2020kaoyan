分布式实时处理系统,原理架构与实现

前言:
云计算 && 大数据 -->海量数据处理和数据挖掘
MapReduce && Bulk Synchronous Parallel

客户要求:服务 价值 数据 便利 -->实时响应

MapReduce是数据批处理 --> 实时处理稍显乏力

数据批处理和数据实时处理的需求有着本质的区别

实时性:及时推送数据 && 数据划分单位
HDFS:存储推送数据-->无法满足实时性要求
Apache Spark提升批处理性能,但是运行机制本身导致不能从根本上解决实时性问题

数据规模的爆炸增长-->数据实时处理的需求-->专注于实时性,规模化的计算平台-->Apache Storm

Storm:可靠的,高容错性的,实时分布式处理平台

本书的目的就是解开面纱,让更多的人少走弯路:Hurricane

高性能的实时处理系统-->高性能的网络层-->支持大量的并发-->跨平台的网络库Meshy,作为Hurricane的传输层

c++11:auto override thread chrono funcational 统一初始化 lambda

分布式计算存储概念-->网络通信基础知识-->网络高层抽象知识
-->C++相关知识-->Hurricane的设计方案-->Hurricane主体功能实现
-->Meshy跨平台网络框架及应用

Hurricane实时处理系统:c++11编写的,高性能为关注点的分布式实时计算框架,
使用流模型作为计算模型,同时提供易于理解的高层接口

第一章:分布式计算概述
分布式概念+分布式系统特性+分布式存储类型+产品实例+对比批处理方案&&Storm流计算模型-->实时处理系统

1.1 分布式概念
互联网没有集中式的控制中心,大量分离且互联的节点组成-->类比到分布式概念上

集中式系统:使用计算能力强大的服务器处理大量的计算任务,其他很多终端作为数据I/O
分布式系统:将海量计算能力的大问题拆解为许多小块,将小块分配给系统中不同的计算节点进行处理,
最后将分开的计算结果合并为最终结果

手段:在不同节点之间进行数据通信和协调,一般指网络消息

一套分布式系统会使用网络上的硬件资源和软件组件进行计算,而各个节点之间通过一定的方式通信

1.2 分布式计算及其原理
分布式计算:将计算任务分摊到大量计算节点上,一起完成海量的计算任务
分布式计算:将一个复杂庞大的计算任务划分为一个个的小任务,分摊到不同的计算节点上,
让其并行执行,而每个计算节点也可以并行处理自身的任务,更加充分利用CPU资源,
最后将每个节点的结果汇总,得到最后的计算结果

步骤:
1. 设计分布式计算模型:各个组件如何运行,如何消息通信,如何管理
2. 任务分配:能否分配,如何分配
3. 编写并执行分布式程序:使用特定的分布式框架和计算模型,将分布式算法转为实现,并保证整个集群的高效运行

1. 计算任务的划分:并行计算互不相干,但分布式节点之间产生数据依赖,任务划分就要合理有效
2. 节点之间高效通信:消息队列:将节点之间的数据依赖变为节点之间的消息传递,
分布式存储系统:将节点的执行结果暂存在数据库中,其他节点等待从数据库中获取数据,

1.3 分布式系统特性
分布式系统中的某台电脑停止运行了,但你的软件却永远不会

特性:容错性,高可扩展性,开放性,并发处理能力和透明性

1.3.1 容错性
应对问题:某个节点发生故障
检测,恢复,和避免整套系统的不可用

检测故障:校验消息和数据有无以及合法性, 网络延迟,消息乱序
故障恢复:回滚正确数据的状态,确保不传递错误数据,事务性
故障避免:消息重发,冗余
一定时间范围内消息不可达时进行重传,多次尝试后仍不可达认为,节点出现问题
数据冗余存储一定程度上可以降低数据出错的概率
冗余的节点,冗余的路由器,冗余的数据库数据

1.3.2 高可扩展性
系统运行过程中自由地对系统内部节点或现有功能进行扩充,而不影响现有服务的运行
1. 更新需要停机
2. 没有开放接口,需要中间层作转换

Storm通过json格式:1. 解决了接口难以扩展和集成的问题 2. 后续节点扩充的问题

1.3.3 开放性
自我扩展和其他系统集成
OpenAPI 最好是遵循某种协议

1.3.4 并发处理能力
并发导致的一致性问题:同步问题
可用性问题:缓冲或加锁会导致可用性

分布式系统CAP特性:
Consistency: 统一数据在集群中的所有节点,在同一时刻是否都是同样的值
Availability: 集群中一部分节点故障后,集群整体是否还能处理客户端的更新请求
Partion Tolerance:是否允许数据的分区,分区是指允许集群中的节点之间无法通信

1.3.5 透明性
将分布式系统当成一个整体给用户看待

1.4 通用分布式计算系统

1.4.1 Apache Hadoop

Hadoop:Apache基金会开发的分布式存储与计算框架,
用户不需要了解分布式计算原理,就可以轻松开发出分布式计算程序,
可以充分利用集群中的闲置的计算资源,将集群的真正威力调用起来.

HDFS:Hadoop分布式文件系统:将文件数据分布式地存储在集群中的不同节点上
MapReduce:针对大量数据的分布式计算系统 : YARN:任务调度和资源管理的框架

1. 历史:Hadoop MapReduce--> Google MapReduce
Hadoop HDFS-->Google GFS

Hadoop:目前世界上最流行的分布式计算框架
Apache: HBase,Cassandra,Avro,Hive,Mahout

2. HDFS
HDFS:主从式的分布式文件系统,是GFS的一种开源实现
HDFS:利用大量廉价存储器组成分布式存储集群,取代昂贵的集中式磁盘存储阵列
HDFS集群:一个NameNode,多个DataNode, Secondary NameNode

1. NameNode:整个集群的管理者,并不存储数据本身,而是存储文件系统的元数据:命名空间,外部客户端的访问
决定将文件内容映射到DataNode数据块上,Secondary NameNode
2. Secondary NameNode:
NameNode会将数据实时备份到Secondary NameNode上
3. DataNode:
实际的数据存储节点
响应NameNode的命令(创建,删除,复制)
NameNode会读取DataNode的心跳,判断DataNode是否活着
同一份数据会存储在多个DataNode上,一旦一个DataNode宕机,NameNode会采取相应策略
4. MapReduce
小块数据-->Map中-->Reduce
Resource_Manager:管理整个集群
Node_Manager:管理某个节点的容器并监视其资源使用
MRAppMaster

3. Apache Hadoop特性
1. 高可靠性:可靠地将数据存储在节点上
2. 高可扩展性:存储和计算节点可以快速扩展,并自动进行负载均衡
3. 高效性:各个节点之间动态调动数据,保证每个节点存储均衡,从不同节点并行读取,提高读取速度
4. 高容错性:将数据冗余存储在不同节点上,保证数据容错性,计算任务失败时也会自动重新分配任务
5. 低成本:开源不用花钱,廉价节点取代超级计算机
缺陷:实时性较差,积累一批数据,然后手动或定时启动MapReduce处理完这批数据,
下一批数据积累一定程度,在进行新一轮任务,而不是随着数据的到来及时处理

为了提高实时性,我们需要增加缓存优化,但是MapReduce的各个任务之间的通信
采用HDFS机制,因此没有实时性

1.4.2 Apache Spark
解决Apache Hadoop计算速度慢的问题
1. 执行速度极快
将中间结果放在内存中而不是HDFS中,提升100倍
2. 支持多种运行模式
除了可以独立在集群上执行任务以外,可以执行在E2C,YARN上,也可以从HDFS,HBase,Hive,Cassandra中读取数据
3. 多种计算模型
SQL接口,Spark流模型,Mlib机器学习接口,GraphX图形计算接口

致命问题:计算模型仍然是任务式的
对于实时流入又要实时反馈的数据,Spark亦无法满足

1.4.3 Apache Storm
海量数据任务的批处理系统在实时计算处理方面越发显得乏力
任务式计算模型和实时处理系统有着本质的区别
